{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目3：人脸识别\n",
    "\n",
    "欢迎来到机器学习工程师纳米学位的第三个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。每一部分都会有详细的指导，需要实现的部分也会在注释中以'TODO'标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还必须回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以'问题 X'为标题。请仔细阅读每个问题，并且在问题后的'回答问题'文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务介绍\n",
    "\n",
    "人脸识别是一个计算机视觉任务，任务是要通过一张带有人脸的图像，对图像中的人脸进行识别并判断是谁。关于人脸识别的任务，我们一定会用到2015年Google开发的FaceNet，这个模型由于其性能非常好而被广泛使用，并且该训练好的模型已经被开源。\n",
    "\n",
    "因此，本项目的任务将要学习人脸识别任务，在此项目中，我们将先按课程所学到的知识亲手搭建一个卷积神经网络，然后，我们将用高级的网络结构，比如ResNet50再次进行人脸识别任务，最后我们将用到预训练好的FaceNet模型。在这个过程中，我们还会用到数据增强和人脸抽取技术来提升人脸识别的精确度。\n",
    "\n",
    "在这个人脸识别项目中，我们将使用一个开源数据集[Five Celebrity Faces Dataset](kaggle.com/dansbecker/5-celebrity-faces-dataset)，这也是一个在Kaggle比赛中的一个数据集。我们也已经下载好了并放在`./5-celebrity-faces-dataset`中，数据集中包含五位名人的照片，Ben Affleck, Elton John, Jerry Seinfeld, Madonna, Mindy Kaling。文件下分`train`和`val`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "我们首先要简单的观察数据，然后通过数据增强和人脸抽取技术对数据图像数据进行抽取。你需要在完成这些操作后，思考并回答相关的问题。\n",
    "\n",
    "### 显示一张图像\n",
    "\n",
    "所有 train下面的图像文件名都存入 images 列表中，并将该图像的人名按顺序存于 images_name 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "data_root = \"./5-celebrity-faces-dataset/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 把所有 train下面的图像文件名都存入 images 列表中，并将该图像的人名按顺序存于 images_name 中\n",
    "images = []\n",
    "images_name = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从`images`中随机读取一张图像，使用 `cv2.imread`读取图像，然后使用`pyplot.imshow`显示图像。注意：你需要同时显示该图像对应的人名，以及打印该图像的`shape`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 从images 中随机读取一张图像，并获得该图像中的人名\n",
    "def random_sample(images=images, images_name=images_name):\n",
    "    print(\"随机选取一张照片：\")\n",
    "    # TODO：从 images 和 images_name 随机读取一个图像文件路径以及该图像的人名\n",
    "    im_file, im_name = \n",
    "    # TODO：使用 cv2.imread 读取图像文件\n",
    "    img = \n",
    "    # TODO：使用 plt.imshow 和 plt.show() 显示图像\n",
    "    \n",
    "    # 打印该图像的人名\n",
    "    print(im_name)\n",
    "    # 打印该图像的大小 shape\n",
    "    print(img.shape)\n",
    "    return im_file, im_name\n",
    "\n",
    "random_sample(images, images_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以多次运行上面的代码来多观察一些人物图像，以此来对数据有一个大致的认知"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用`cv2.imread`读取所有数据并存入`train_x`中，然后用 0,1,2,3,4 来标记 Ben Affleck, Elton John, Jerry Seinfeld, Madonna, Mindy Kaling，并将所有`images_name`数据存入`train_y`中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强\n",
    "\n",
    "首先，我们需要打印训练集的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，训练集的图像数量比较少，这对模型建模并学习图像数据到人名标签的映射关系增加了难度，所以这里需要做数据增强的工作。这里有一份很不错的资料可以帮助你了解数据增强——[Data Augmentation](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# TODO: 构造图像数据增强器\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale = , # TODO：随机缩放图像RGB值的倍数\n",
    "    rotation_range = , # TODO：随机旋转图像的范围\n",
    "    zoom_range = ,  # TODO：随机缩放图像大小范围\n",
    "    width_shift_range = ,  # TODO：随机水平方向平移图像(fraction of total width)\n",
    "    height_shift_range= ,  # TODO：随机纵向平移图像(fraction of total height)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `flow_from_directory` 遍历数据集 `./5-celebrity-faces-dataset/data`，来观察数据增强的表现。先得到一个图像迭代器，该迭代器每次都从路径里读取一个图像，并按照数据增强器的规则进行编辑图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行，得到一个图像迭代器，该迭代器每次都从路径里读取一个图像，并按照数据增强器的规则进行编辑图像\n",
    "dataflow_generator = data_gen.flow_from_directory(\n",
    "    \"./5-celebrity-faces-dataset/data\",\n",
    "    target_size=(160, 160),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：从 迭代器中 读取10张图片，并显示图像\n",
    "\n",
    "sample_count = 10\n",
    "for image_data in dataflow_generator:\n",
    "    # TODO：使用 plt.imshow 和 plt.show() 显示图像\n",
    "\n",
    "    \n",
    "    sample_count -= 1\n",
    "    if sample_count <= 0:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题1**：观察以上人脸图像，简单说说产生的图像中存在哪些增强的部分，然后再详细阐述你对数据增强的思考，包括为什么数据增强能够帮助人脸识别？你需要参考一些论文，并列出你的引用。\n",
    "\n",
    "**问题回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人脸抽取\n",
    "\n",
    "在做人脸识别任务中，一项常用的图像数据处理的技术是人脸检测（Face Detection）。人脸检测是将输入的图片中的人脸部分自动检测出来，具体来说就是要通过预测一个矩形边界框（Bounding Box）从整个图像中定位人脸部分，这里的矩形边界框由矩形左下角坐标以及矩形高和宽来定义。人脸检测是一个比较成熟的任务，接下来在我们这个项目中，我们将使用 Multi-Task Cascaded Convolutional Neural Network，MTCNN，你也可以参考论文：[Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks](https://arxiv.org/abs/1604.02878)，来学习人脸检测任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行下面代码，安装 mtcnn\n",
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义人脸抽取的函数\n",
    "from PIL import Image\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "\n",
    "def extract_face(filename, image_size=(160, 160)):\n",
    "    # 加载图像\n",
    "    image = Image.open(filename)\n",
    "    # 转换RGB\n",
    "    image = image.convert('RGB')\n",
    "    # 转成 numpy.array 格式的数据\n",
    "    image_data = np.asarray(image)\n",
    "    # 创建一个人脸检测，\n",
    "    detector = MTCNN()\n",
    "    # 从图像中检测\n",
    "    results = detector.detect_faces(image_data)\n",
    "    # 返回的结果是图像中所有出现的人脸的矩形边界框，由于我们的图像中只有一张人脸，所所以只需要取结果中第一个\n",
    "    box_x, box_y, width, height = results[0]['box']\n",
    "    # 处理下标为负的情况\n",
    "    box_x, box_y = abs(box_x), abs(box_y)\n",
    "    box_x_up, box_y_up = box_x + width, box_y + height\n",
    "    # 获得人脸部分的数据\n",
    "    face = image_data[box_y:box_y_up, box_x:box_x_up]\n",
    "    \n",
    "    # TODO：把抽取出来的人脸图像 resize 至需要的图像大小，并返回numpy格式的数据\n",
    "    face_array = \n",
    "    return face_array\n",
    "\n",
    "ran_img_file, ran_img_name = random_sample()\n",
    "img = extract_face(ran_img_file)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题2：**通过多次运行以上代码并观察人脸抽取后的图像，你认为人脸检测对人脸识别有帮助吗？为什么？你需要参考一些论文，并列出你的reference。\n",
    "\n",
    "**回答问题：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造数据\n",
    "\n",
    "现在我们可以应用以上的数据增强和人脸检测技术来构造完整的数据。\n",
    "\n",
    "这里可以直接使用前面定义好的图像数据增强器 `data_gen`，然后使用 [ImageDataGenerator](https://keras.io/preprocessing/image/)中的 `random_transform` 对单个图像做随机增强操作。\n",
    "\n",
    "另外，在构造数据之前，你需要先构造一个人名到类别的映射，使得在构造数据的label的时候将string格式的人名转换为int格式的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编程练习：\n",
    "1. 你需要 构造人名字典，将 ben_afflek、elton_john、jerry_seinfeld、madonna、mindy_kaling 分别映射到 0-1-2-3-4\n",
    "2. 定义 `load_dataset`函数，遍历train或者val文件夹，读取文件夹下5个人名文件夹，以该文件夹名映射至0到4 的标签；然后分别从人名文件夹中遍历所有图像文件，读取图像，如果是train文件夹下的图像，则需要用`data_gen.random_transform`来增强图像数据，增强次数为augment_times；如果是val文件夹下的图像，则不需要进行图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO：构造人名字典，将 ben_afflek、elton_john、jerry_seinfeld、madonna、mindy_kaling 分别映射到 0-1-2-3-4\n",
    "name_dict = \n",
    "\n",
    "# TODO：定义数据加载函数，data_dir为文件路径，augment_times为数据增强次数，is_train为判断是训练集还是测试集（测试集不需要数据增强）\n",
    "def load_dataset(data_dir = \"./5-celebrity-faces-dataset/train/\", augment_times=2, is_train=True):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    # TODO:\n",
    "                \n",
    "    return data_x, data_y\n",
    "\n",
    "train_x, train_y = load_dataset(\"./5-celebrity-faces-dataset/train/\", augment_times=2, is_train=True)\n",
    "test_x, test_y = load_dataset(\"./5-celebrity-faces-dataset/val/\", is_train=False)\n",
    "\n",
    "# 最终构造好训练和测试数据\n",
    "train_X = np.asarray(train_x)\n",
    "train_Y = np.eye(5)[np.array(train_y)]\n",
    "test_X = np.asarray(test_x)\n",
    "test_Y = np.eye(5)[np.array(test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建一个卷积神经网络\n",
    "\n",
    "创建一个卷积神经网络来对人脸进行分类。在你代码块的最后，执行 `model.summary()` 来输出你模型的总结信息。\n",
    "。\n",
    "\n",
    "![Sample CNN](images/sample_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3：**在下方的代码块中尝试使用 Keras 搭建卷积网络的架构，并回答相关的问题。\n",
    "\n",
    "1. 你可以尝试自己搭建一个卷积网络的模型，那么你需要回答你搭建卷积网络的具体步骤（用了哪些层）以及为什么这样搭建。\n",
    "2. 你也可以根据上图提示的步骤搭建卷积网络，那么请说明如上的架构能够在该问题上取得的表现。\n",
    "\n",
    "\n",
    "**回答问题：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: 定义你的网络架构\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行编译模型和训练模型\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# 模型训练\n",
    "model.fit(train_X, train_Y, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型测试\n",
    "\n",
    "你需要编写一个自动测试模型准确率的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_accuracy(model, test_X, test_Y, model_name)\n",
    "    preds_Y = model.predict(test_X)\n",
    "    #TODO：通过预测值preds_Y以及真实值test_Y，来计算准确率\n",
    "    \n",
    "    accuracy = \n",
    "    \n",
    "    print(\"%s Accuracy: %.3f\" % (model_name, accuracy))\n",
    "    \n",
    "metric_accuracy(model, test_X, test_Y, \"Simple CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进阶 CNN 模型架构\n",
    "在计算机视觉任务中，有一些复杂的高级CNN模型架构，比如ResNet、VGG、Inception 等等，他们能够对图像有一个非常好的表达。并且，已经有人把这些模型在非常大的图像数据上训练好了参数，这使得预训练的大模型能够对图像有一个很好的特征表达。这种在大规模图像数据上学到的图像特征，能够迁移到人脸图像的特征表示。\n",
    "\n",
    "在这一小节，我们利用预训练好的 ResNet50,抽取图像特征，然后再去做人脸识别。虽然 ResNet50 在各种图像上面进行预训练的，但是该模型对图像结构特征信息的学习也能够帮助人脸识别任务中的预测。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# 模型底层使用 ResNet50 对原始图像进行建模，特征抽取\n",
    "resnet50_weights = \"./models/resnet50_weights.h5\"\n",
    "resnet = keras.applications.resnet50.ResNet50(weights=None, include_top=False, input_shape=(160, 160, 3))\n",
    "resnet.load_weights(resnet50_weights)\n",
    "\n",
    "# TODO：自己定义模型顶层，使用抽取后的特征进行人脸识别\n",
    "resnet_face = Sequential()\n",
    "resnet_face.add(Flatten(input_shape=resnet.output_shape[1:]))\n",
    "resnet_face.add()\n",
    "\n",
    "\n",
    "resnet_face_model = Model(inputs=resnet.input, outputs=resnet_face(resnet.output))\n",
    "# resnet_face_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置同样的训练参数，直接运行\n",
    "\n",
    "## 编译模型\n",
    "resnet_face_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# 模型训练\n",
    "resnet_face_model.fit(train_X, train_Y, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行，测试 resnet_face_model 的准确率\n",
    "metric_accuracy(resnet_face_model, test_X, test_Y, \"ResNet50\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题5：**对比 ResNet50 模型和 CNN 模型的结果，请你分析为什么 ResNet50 模型能够取得更好的结果？\n",
    "\n",
    "**回答问题：**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题6：**上面我们使用了预训练好的 ResNet50，即`resnet.load_weights(resnet50_weights)`，那么加载预训练好的参数对该任务有帮助吗？你需要通过做对比实验，即不加载预训练好的参数，然后在下面的代码框中重新跑一遍 ResNet50 的模型，来作为对比说明加载预训练是否有帮助\n",
    "\n",
    "**回答问题：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新跑一遍不加载预训练参数的 ResNet50 的模型，请在此处写完整的code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet \n",
    "\n",
    "上一小节中，我们利用了预训练好的 ResNet50 来抽取图像特征，而这一小节我们将利用预训练好的 FaceNet 来抽取人脸特征。我们已经知道 ResNet50 是在大规模数据上建模学习图像特征的，这里面的数据是多种多样的，不限制于人脸图像，而 [FaceNet](https://arxiv.org/pdf/1503.03832.pdf) 是专门对于人脸进行特征抽取的工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：使用 load_model 从`./models/facenet_keras.h5` 加载模型\n",
    "from keras.models import load_model\n",
    "\n",
    "# 模型底层使用 FaceNet 对原始图像进行建模，特征抽取\n",
    "# 加载预训练好的 FaceNet 模型。\n",
    "facenet_model = \n",
    "print(\"FaceNet model loaded...\")\n",
    "\n",
    "# TODO：自己定义模型顶层，使用抽取后的特征进行人脸识别\n",
    "facenet_face = Sequential()\n",
    "facenet_face.add()\n",
    "\n",
    "\n",
    "facenet_face_model = Model(inputs=facenet_model.input, outputs=facenet_face(facenet_model.output))\n",
    "# facenet_face_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XX = []\n",
    "for x in train_X:\n",
    "    x_image = Image.fromarray(x)\n",
    "    x_image = x_image.resize((160, 160))\n",
    "    train_XX.append(np.asarray(x_image))\n",
    "train_X = np.array(train_XX)\n",
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 编译模型\n",
    "facenet_face_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# 模型训练\n",
    "facenet_face_model.fit(train_X, train_Y, batch_size=8, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_XX = []\n",
    "for x in test_X:\n",
    "    x_image = Image.fromarray(x)\n",
    "    x_image = x_image.resize((160, 160))\n",
    "    test_XX.append(np.asarray(x_image))\n",
    "test_X = np.array(test_XX)\n",
    "test_X[0].shape\n",
    "\n",
    "preds_Y = facenet_face_model.predict(test_X)\n",
    "correct = 0.\n",
    "for pr, y in zip(preds_Y, test_Y):\n",
    "    pr_cls = np.argmax(pr)\n",
    "    if y[pr_cls] == 1:\n",
    "        correct += 1\n",
    "accuracy = correct / len(preds_Y)\n",
    "print(\"FaceNet Accuracy: %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题7：**评价 FaceNet 模型的效果，并指出为什么 FaceNet 比上一小节中 ResNet 的效果要好。\n",
    "\n",
    "**回答问题：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题8：**\n",
    "- 首先你需要在下放画一个表格，将上面所做的实验结果都列出来。\n",
    "- 然后总结此项目，你认为在这个**人脸识别**项目中，哪些技术对识别准确率起比较重要的作用？请结合以上的实验结果分析。\n",
    "- 最后，你再简要说说还有哪些技术对人脸识别任务有较大的帮助？列出你的references\n",
    "\n",
    "**回答问题：**\n",
    "实验结果总结\n",
    "\n",
    "|Models|Accuracy|\n",
    "|---|---|\n",
    "|CNN|#|\n",
    "|ResNet50 no-pretrain|#|\n",
    "|ResNet50 pretrain|#|\n",
    "|FaceNet|#|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
